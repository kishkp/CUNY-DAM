n <- 1
for(i in 2:length(hams)){
tmp <- readLines(hams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(ham_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(ham_mail))
ham_corpus <- c(ham_corpus, tmp_corpus)
meta(ham_corpus[[1]], "EmailType") <- "Ham"
}
}
email_corpus <- c(spam_corpus, ham_corpus)
meta_EmailType <- meta(email_corpus, type = "local", tag = "EmailType")
meta_data <- data.frame(
EmailType = unlist(meta_EmailType)
)
View(meta_data)
View(meta_data)
email_corpus <- tm_map(email_corpus, removeWords, words = stopwords("en"))
#email_corpus <- tm_map(email_corpus, tolower)
email_corpus <- tm_map(email_corpus, stemDocument)
email_corpus <- tm_map(email_corpus, PlainTextDocument)
tdm <- TermDocumentMatrix(email_corpus)
tdm <- removeSparseTerms(tdm, 1-(10/length(email_corpus)))
dtm <- DocumentTermMatrix(email_corpus)
dtm <- removeSparseTerms(dtm, 1-(10/length(email_corpus)))
EmailType_labels <- unlist(meta(email_corpus, "EmailType"))
N <- length(EmailType_labels)
EmailType_labels
meta(email_corpus, "EmailType")
meta(ham_corpus, "EmailType")
library(RCurl)
library(XML)
library(stringr)
library(tm)
library(SnowballC)
library(RTextTools)
# first we parse all the spams and create the email corpus
spams <- dir("./emails/spam/", full.names = TRUE)
tmp <- readLines(spams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
spam_corpus <- Corpus(VectorSource(spam_mail))
meta(spam_corpus[[1]], "EmailType") <- "Spam"
n <- 1
for(i in 2:length(spams)){
tmp <- readLines(spams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(spam_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(spam_mail))
spam_corpus <- c(spam_corpus, tmp_corpus)
meta(spam_corpus[[n]], "EmailType") <- "Spam"
}
}
# next we parse all the hams and add to the email corpus
hams <- dir("./emails/easy_ham/", full.names = TRUE)
tmp <- readLines(hams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
ham_corpus <- Corpus(VectorSource(ham_mail))
meta(ham_corpus[[1]], "EmailType") <- "Ham"
n <- 1
for(i in 2:length(hams)){
tmp <- readLines(hams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(ham_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(ham_mail))
ham_corpus <- c(ham_corpus, tmp_corpus)
meta(ham_corpus[[n]], "EmailType") <- "Ham"
}
}
# We combine both the corpus
email_corpus <- c(spam_corpus, ham_corpus)
meta_EmailType <- meta(email_corpus, type = "local", tag = "EmailType")
meta_data <- data.frame(
EmailType = unlist(meta_EmailType)
)
unlist(meta_EmailType)
email_corpus <- tm_map(email_corpus, removeWords, words = stopwords("en"))
#email_corpus <- tm_map(email_corpus, tolower)
email_corpus <- tm_map(email_corpus, stemDocument)
email_corpus <- tm_map(email_corpus, PlainTextDocument)
tdm <- TermDocumentMatrix(email_corpus)
tdm <- removeSparseTerms(tdm, 1-(10/length(email_corpus)))
dtm <- DocumentTermMatrix(email_corpus)
dtm <- removeSparseTerms(dtm, 1-(10/length(email_corpus)))
EmailType_labels <- unlist(meta(email_corpus, "EmailType"))
N <- length(EmailType_labels)
meta(email_corpus, "EmailType")
View(meta_data)
View(meta_data)
meta(email_corpus)
email_corpus <- c(spam_corpus, ham_corpus)
meta_EmailType <- meta(email_corpus, type = "local", tag = "EmailType")
meta_EmailType
email_corpus
spam_corpus
library(RCurl)
library(XML)
library(stringr)
library(tm)
library(SnowballC)
library(RTextTools)
spams <- dir("./emails/spam/", full.names = TRUE)
tmp <- readLines(spams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
spam_corpus <- Corpus(VectorSource(spam_mail))
meta(spam_corpus[[1]], "EmailType") <- "Spam"
spams <- dir("./emails/spam/", full.names = TRUE)
tmp <- readLines(spams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
spam_corpus <- Corpus(VectorSource(spam_mail))
meta(spam_corpus[[1]], "EmailType") <- "Spam"
n <- 1
for(i in 2:length(spams)){
tmp <- readLines(spams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(spam_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(spam_mail))
spam_corpus <- c(spam_corpus, tmp_corpus)
meta(spam_corpus[[n]], "EmailType") <- "Spam"
}
}
spam_corpus
meta_EmailType <- meta(spam_corpus, type = "local", tag = "EmailType")
meta_EmailType[1]
hams <- dir("./emails/easy_ham/", full.names = TRUE)
tmp <- readLines(hams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
ham_corpus <- Corpus(VectorSource(ham_mail))
meta(ham_corpus[[1]], "EmailType") <- "Ham"
n <- 1
for(i in 2:length(hams)){
tmp <- readLines(hams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(ham_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(ham_mail))
ham_corpus <- c(ham_corpus, tmp_corpus)
meta(ham_corpus[[n]], "EmailType") <- "Ham"
}
}
email_corpus <- c(spam_corpus, ham_corpus)
meta_EmailType <- meta(email_corpus, type = "local", tag = "EmailType")
meta_EmailType[1]
meta_EmailType[500]
meta_EmailType[501]
meta_EmailType <- meta(ham_corpus, type = "local", tag = "EmailType")
email_corpus <- c(spam_corpus, ham_corpus)
meta_EmailType[500]
meta_EmailType[1]
library(RCurl)
library(XML)
library(stringr)
library(tm)
library(SnowballC)
library(RTextTools)
# first we parse all the spams and create the email corpus
spams <- dir("./emails/spam/", full.names = TRUE)
tmp <- readLines(spams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
spam_corpus <- Corpus(VectorSource(spam_mail))
meta(spam_corpus[[1]], "EmailType") <- "Spam"
n <- 1
for(i in 2:length(spams)){
tmp <- readLines(spams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(spam_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(spam_mail))
spam_corpus <- c(spam_corpus, tmp_corpus)
meta(spam_corpus[[n]], "EmailType") <- "Spam"
}
}
meta_spam <- meta(spam_corpus, type = "local", tag = "EmailType")
# next we parse all the hams and add to the email corpus
hams <- dir("./emails/easy_ham/", full.names = TRUE)
tmp <- readLines(hams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
ham_corpus <- Corpus(VectorSource(ham_mail))
meta(ham_corpus[[1]], "EmailType") <- "Ham"
n <- 1
for(i in 2:length(hams)){
tmp <- readLines(hams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(ham_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(ham_mail))
ham_corpus <- c(ham_corpus, tmp_corpus)
meta(ham_corpus[[n]], "EmailType") <- "Ham"
}
}
# We combine both the corpus
meta_ham <- meta(ham_corpus, type = "local", tag = "EmailType")
meta_spam[1]
meta_spam[500]
meta_spam[13309]
meta_spam[40000]
meta_spam[13309]
meta_spam[13308]
meta_spam[2]
meta_spam[4]
meta_spam[100]
meta_ham[1]
email_corpus <- c(spam_corpus, ham_corpus)
meta_EmailType <- meta(email_corpus, type = "local", tag = "EmailType")
meta_EmailType[1]
meta_EmailType[500]
meta_EmailType[14000]
meta_data <- data.frame(
EmailType = unlist(meta_EmailType)
)
View(meta_data)
View(meta_data)
email_corpus <- tm_map(email_corpus, removeWords, words = stopwords("en"))
#email_corpus <- tm_map(email_corpus, tolower)
email_corpus <- tm_map(email_corpus, stemDocument)
email_corpus <- tm_map(email_corpus, PlainTextDocument)
tdm <- TermDocumentMatrix(email_corpus)
tdm <- removeSparseTerms(tdm, 1-(10/length(email_corpus)))
dtm <- DocumentTermMatrix(email_corpus)
dtm <- removeSparseTerms(dtm, 1-(10/length(email_corpus)))
dtm
EmailType_labels <- unlist(meta(email_corpus, "EmailType"))
EmailType_labels
meta(email_corpus)
View(meta_data)
View(meta_data)
meta(email_corpus, "EmailType")
library(RCurl)
library(XML)
library(stringr)
library(tm)
library(SnowballC)
library(RTextTools)
# first we parse all the spams and create the email corpus
spams <- dir("./emails/spam/", full.names = TRUE)
tmp <- readLines(spams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
spam_corpus <- Corpus(VectorSource(spam_mail))
meta(spam_corpus[[1]], "EmailType") <- "Spam"
n <- 1
for(i in 2:length(spams)){
tmp <- readLines(spams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(spam_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(spam_mail))
spam_corpus <- c(spam_corpus, tmp_corpus)
meta(spam_corpus[[n]], "EmailType") <- "Spam"
}
}
meta_spam <- meta(spam_corpus, type = "local", tag = "EmailType")
# next we parse all the hams and add to the email corpus
hams <- dir("./emails/easy_ham/", full.names = TRUE)
tmp <- readLines(hams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
ham_corpus <- Corpus(VectorSource(ham_mail))
meta(ham_corpus[[1]], "EmailType") <- "Ham"
n <- 1
for(i in 2:length(hams)){
tmp <- readLines(hams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(ham_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(ham_mail))
ham_corpus <- c(ham_corpus, tmp_corpus)
meta(ham_corpus[[n]], "EmailType") <- "Ham"
}
}
# We combine both the corpus
meta_ham <- meta(ham_corpus, type = "local", tag = "EmailType")
email_corpus <- c(spam_corpus, ham_corpus)
meta_EmailType <- meta(email_corpus, type = "local", tag = "EmailType")
meta_data <- data.frame(
EmailType = unlist(meta_EmailType)
)
dtm <- DocumentTermMatrix(email_corpus)
dtm <- removeSparseTerms(dtm, 1-(10/length(email_corpus)))
dtm
org_labels <- unlist(meta(release_corpus, "EmailType"))
org_labels <- unlist(meta(email_corpus, "EmailType"))
org_labels
EmailType_labels <- unlist(meta(email_corpus, "EmailType"))
EmailType_labels
meta_data <- data.frame(
EmailType = unlist(meta_EmailType)
)
library(caret)
install.packages("caret")
library(caret)
length(EmailType_labels)*0.75
container <- create_container(dtm, labels = EmailType_labels, trainSize = length(EmailType_labels)*0.75, testSize = length(EmailType_labels)*0.25, virgin = FALSE)
svm_model <- train_model(container, "SVM")
tree_model <- train_model(container, "TREE")
maxent_model <- train_model(container, "MAXENT")
svm_model <- train_model(container, "SVM")
tree_model <- train_model(container, "TREE")
tree_out <- classify_model(container, tree_model)
email_corpus<- sample(email_corpus, length(email_corpus), length(email_corpus))
meta_EmailType <- meta(email_corpus, type = "local", tag = "EmailType")
meta_data <- data.frame(
EmailType = unlist(meta_EmailType)
)
View(meta_data)
View(meta_data)
email_corpus <- tm_map(email_corpus, removeWords, words = stopwords("en"))
email_corpus <- tm_map(email_corpus, stemDocument)
dtm <- DocumentTermMatrix(email_corpus)
dtm <- removeSparseTerms(dtm, 1-(10/length(email_corpus)))
EmailType_labels <- unlist(meta(email_corpus, "EmailType"))
EmailType_labels
N <- length(EmailType_labels)
(N*0.75)
round(N*0.75,0)
Three_4th <- round(N*0.75,0)
EmailType_labels <- unlist(meta(email_corpus, "EmailType"))
N <- length(EmailType_labels)
Three_4th <- round(N*0.75,0)
container <- create_container(dtm, labels = EmailType_labels, trainSize = 1:Three_4th, testSize = Three_4th+1:N, virgin = FALSE)
dtm
library(RCurl)
library(XML)
library(stringr)
library(tm)
library(SnowballC)
library(RTextTools)
library(caret)
# first we parse all the spams and create the email corpus
spams <- dir("./emails/spam/", full.names = TRUE)
tmp <- readLines(spams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
spam_corpus <- Corpus(VectorSource(spam_mail))
meta(spam_corpus[[1]], "EmailType") <- "Spam"
n <- 1
for(i in 2:length(spams)){
tmp <- readLines(spams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(spam_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(spam_mail))
spam_corpus <- c(spam_corpus, tmp_corpus)
meta(spam_corpus[[n]], "EmailType") <- "Spam"
}
}
meta_spam <- meta(spam_corpus, type = "local", tag = "EmailType")
# next we parse all the hams and add to the email corpus
hams <- dir("./emails/easy_ham/", full.names = TRUE)
tmp <- readLines(hams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
ham_corpus <- Corpus(VectorSource(ham_mail))
meta(ham_corpus[[1]], "EmailType") <- "Ham"
n <- 1
for(i in 2:length(hams)){
tmp <- readLines(hams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(ham_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(ham_mail))
ham_corpus <- c(ham_corpus, tmp_corpus)
meta(ham_corpus[[n]], "EmailType") <- "Ham"
}
}
# We combine both the corpus
meta_ham <- meta(ham_corpus, type = "local", tag = "EmailType")
email_corpus <- c(spam_corpus, ham_corpus)
email_corpus<- sample(email_corpus, length(email_corpus), length(email_corpus))
meta_EmailType <- meta(email_corpus, type = "local", tag = "EmailType")
meta_data <- data.frame(
EmailType = unlist(meta_EmailType)
)
meta_data <- data.frame(
EmailType = unlist(meta_EmailType)
)
email_corpus <- tm_map(email_corpus, removeWords, words = stopwords("en"))
email_corpus <- tm_map(email_corpus, stemDocument)
tdm <- TermDocumentMatrix(email_corpus)
tdm <- removeSparseTerms(tdm, 1-(10/length(email_corpus)))
dtm <- DocumentTermMatrix(email_corpus)
dtm <- removeSparseTerms(dtm, 1-(10/length(email_corpus)))
EmailType_labels <- unlist(meta(email_corpus, "EmailType"))
N <- length(EmailType_labels)
Three_4th <- round(N*0.75,0)
container <- create_container(dtm, labels = EmailType_labels, trainSize = 1:Three_4th, testSize = Three_4th+1:N, virgin = FALSE)
dtm
meta(dtm)
View(meta_data)
View(meta_data)
EmailType_labels <- unlist(meta(email_corpus, "EmailType"))
container <- create_container(dtm, labels = EmailType_labels, trainSize = 1:Three_4th, testSize = Three_4th+1:N, virgin = TRUE)
tree_model <- train_model(container, "TREE")
tree_out <- classify_model(container, tree_model)
labels_out <- data.frame(
correct_label = EmailType_labels[Three_4th+1:N],
tree = as.character(tree_out[,1]),
stringsAsFactors = F)
table(labels_out[,1] == labels_out[,3])
prop.table(table(labels_out[,1] == labels_out[,3]))
labels_out
View(labels_out)
View(labels_out)
head(labels_out)
table(labels_out[,1] == labels_out[,3])
labels_out[,1]
labels_out[,3]
View(labels_out)
View(labels_out)
table(labels_out[,1] == labels_out[,2])
prop.table(table(labels_out[,1] == labels_out[,2]))
prop.table(table(labels_out[,1] == labels_out[,2]))[1]
prop.table(table(labels_out[,1] == labels_out[,2]))[2]
library(RCurl)
library(XML)
library(stringr)
library(tm)
library(SnowballC)
library(RTextTools)
library(caret)
# first we parse all the spams and create the email corpus
spams <- dir("./emails/spam/", full.names = TRUE)
tmp <- readLines(spams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
spam_corpus <- Corpus(VectorSource(spam_mail))
meta(spam_corpus[[1]], "EmailType") <- "Spam"
n <- 1
for(i in 2:length(spams)){
tmp <- readLines(spams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
spam_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(spam_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(spam_mail))
spam_corpus <- c(spam_corpus, tmp_corpus)
meta(spam_corpus[[n]], "EmailType") <- "Spam"
}
}
meta_spam <- meta(spam_corpus, type = "local", tag = "EmailType")
# next we parse all the hams and add to the email corpus
hams <- dir("./emails/easy_ham/", full.names = TRUE)
tmp <- readLines(hams[1])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
ham_corpus <- Corpus(VectorSource(ham_mail))
meta(ham_corpus[[1]], "EmailType") <- "Ham"
n <- 1
for(i in 2:length(hams)){
tmp <- readLines(hams[i])
tmp <- htmlParse(tmp[seq(which(tmp == "")[1] + 1, length(tmp), 1)])
ham_mail <- xpathSApply(tmp, "//text()[not(ancestor::script)] [not(ancestor::style)] [not(ancestor::noscript)] [not(ancestor::form)]", xmlValue)
if (length(ham_mail)!=0) {
n <- n + 1
tmp_corpus <- Corpus(VectorSource(ham_mail))
ham_corpus <- c(ham_corpus, tmp_corpus)
meta(ham_corpus[[n]], "EmailType") <- "Ham"
}
}
# We combine both the corpus
meta_ham <- meta(ham_corpus, type = "local", tag = "EmailType")
email_corpus <- c(spam_corpus, ham_corpus)
#randomize the rows
email_corpus<- sample(email_corpus, length(email_corpus), length(email_corpus))
meta_EmailType <- meta(email_corpus, type = "local", tag = "EmailType")
meta_data <- data.frame(
EmailType = unlist(meta_EmailType)
)
# remove Stopwords
#email_corpus <- tm_map(email_corpus, str_replace_all, pattern = "[[:punct:]]", replacement = " ")
email_corpus <- tm_map(email_corpus, removeWords, words = stopwords("en"))
#email_corpus <- tm_map(email_corpus, tolower)
email_corpus <- tm_map(email_corpus, stemDocument)
#email_corpus <- tm_map(email_corpus, PlainTextDocument)
tdm <- TermDocumentMatrix(email_corpus)
tdm <- removeSparseTerms(tdm, 1-(10/length(email_corpus)))
dtm <- DocumentTermMatrix(email_corpus)
dtm <- removeSparseTerms(dtm, 1-(10/length(email_corpus)))
EmailType_labels <- unlist(meta(email_corpus, "EmailType"))
N <- length(EmailType_labels)
Three_4th <- round(N*0.75,0)
container <- create_container(dtm, labels = EmailType_labels, trainSize = 1:Three_4th, testSize = Three_4th+1:N, virgin = TRUE)
tree_model <- train_model(container, "TREE")
tree_out <- classify_model(container, tree_model)
labels_out <- data.frame(
correct_label = EmailType_labels[Three_4th+1:N],
tree = as.character(tree_out[,1]),
stringsAsFactors = F)
table(labels_out[,1] == labels_out[,2])
prop.table(table(labels_out[,1] == labels_out[,2]))
